---
title: "Usage"
---

Ribasim is typically used as a command-line interface (CLI). It is distributed as a `.zip`
archive, that must be downloaded and unpacked. It can be placed anywhere, however it is
important that the contents of the zip file are kept together in a directory. The Ribasim
CLI executable is in the `bin` directory.

The latest build can be downloaded here: [ribasim_cli.zip](https://ribasim.s3.eu-west-3.amazonaws.com/teamcity/Ribasim_Ribasim/BuildRibasimCliWindows/latest/ribasim_cli.zip).
Currently only Windows builds are available.

To check whether the installation was performed successfully, run `ribasim` with no
arguments in the command line.
This will give the following message:

```
Usage: ribasim 'path/to/config.toml'
```


## Input and output files

### Configuration file

Ribasim has a single configuration file, which is written in the [TOML](https://toml.io/)
format. It contains settings, as well as paths to other input and output files.

```toml
# start- and endtime of the simulation
# can also be set to a date-time like 1979-05-27T07:32:00
starttime = 2019-01-01  # required
endtime = 2021-01-01    # required

# all timesteps are in seconds
update_timestep = 86400.0  # optional, default 1 day

# input files
geopackage = "model.gpkg"  # required

# These output files are always written
flow = "output/flow.arrow"    # optional, default "output/flow.arrow"
basin = "output/basin.arrow"  # optional, default "output/basin.arrow"

# Specific tables can also go into Arrow files rather than the GeoPackage.
# For large tables this can benefit from better compressed file sizes.
# This is optional, tables are retrieved from the GeoPackage if not specified in the TOML.
[Basin]
forcing = "forcing.arrow"


[solver]
algorithm = "QNDF"  # optional, default "QNDF"
# autodiff can only be set to true for implicit solvers, but is not yet supported
autodiff = false  # optional, default false
# saveat can be a number, which is the saving interval in seconds, or
# it can be a list of numbers, which are the times in seconds since start that are saved
saveat = []  # optional, default [], which will save every timestep
dt = 0.0  # optional, default 0.0
abstol = 1e-6  # optional, default 1e-6
reltol = 1e-3  # optional, default 1e-3
maxiters = 1e9  # optional, default 1e9
```

For more information on the solver options, see the [DifferentialEquations.jl docs](https://docs.sciml.ai/DiffEqDocs/latest/basics/common_solver_opts/#solver_options).
Information on the solver algorithms can be found on the [ODE solvers page](https://docs.sciml.ai/DiffEqDocs/stable/solvers/ode_solve/).

### GeoPackage and Arrow tables

The input and output tables described below all share that they are tabular files. The Node
and Edge tables always have to be in the [GeoPackage](https://www.geopackage.org/) file, and
output is always written to [Apache Arrow](https://arrow.apache.org/) files, sometimes also
known as Feather files. All other tables can either be in the GeoPackage or in separate
Arrow files that are listed in the TOML as described above.

For visualization, the Node and Edge tables typically have associated geometries. GeoPackage
was used since it provides a standardized way to store tables with (and without) geometry
columns in a SQLite database. If, like Ribasim, you can ignore the geometries, a GeoPackage
is easy to read using SQLite libraries, which are commonly available. Furthermore GeoPackage
can be updated in place when working on a model.

Arrow was chosen since it is standardized, fast, simple and flexible. It can be read and
written by many different software packages. In Ribasim we use
[Arrow.jl](https://arrow.juliadata.org/dev/). Output is written to Arrow, since for long
runs output can producs tables with many rows. Arrow is well suited for large tabular
datasets, and file size is kept small by using compression. The Arrow input files can be
compressed with LZ4 or Zstd compression. Furthermore, in some of the columns, a small amount
of different values are repeated many times. To reduce file sizes it may be a good idea to
apply [dictionary
encoding](https://arrow.apache.org/docs/format/Columnar.html#dictionary-encoded-layout) to
those columns.

Below we give details per file, in which we describe the schema of the table using a syntax
like this:

column    | type    | unit         | restriction
--------- | ------- | ------------ | -----------
node_id   | Int     | -            | sorted
storage   | Float64 | $m^3$        | non-negative

This means that two columns are required, one named `node_id`, that contained elements of
type `Int`, and a column named `storage` that contains elements of type `Float64`. The order
of the columns does not matter. In some cases there may be restrictions on the values. This
is indicated under `restriction`.

Tables are also allowed to have rows for timestamps that are not part of the simulation,
these will be ignored. That makes it easy to prepare data for a larger period, and test
models on a shorted period.

### Node

Node is a table that specifies the ID and type of each node of a model. The ID must be
unique among all nodes, and the type must be one of the available node types listed below.

Nodes are components that are connected together to form a larger system. The Basin is a
central node type that stores water. The other node types influence the flow between Basins
in some way. Counter intuitively, even systems you may think of as edges, such as a canal,
are nodes in Ribasim. This is because edges only define direct instantaneous couplings
between nodes, and never have storage of their own.

column    | type     | restriction
--------- | -------- | -----------
fid       | Int      | unique, sorted
type      | String   | known node type
geometry  | geoarrow | (optional)

The available node types as of this writing are listed as the top level bullets below. The
sub-bullets indicate which tables are associated to the node type. The table name is the
name it must have in the GeoPackage if it is stored there.

- Basin: stores water
  - `Basin / static`: default forcing values, used if no dynamic data given in the forcing table
  - `Basin / profile`: geometries of the basins
  - `Basin / forcing`: time series of the forcing values
  - `Basin / state`: used as initial condition of the basins
- FractionalFlow: connect two of these from a Basin to get a fixed ratio bifurcation
  - `FractionalFlow / static`: fractions
- LevelBoundary: stores water at a given level unaffected by flow, like an infinitely large basin
  - `LevelBoundary / static`: levels
- FlowBoundary: sets a precribed flow like a one-sided pump
  - `FlowBoundary / static`: flow rate
- LinearResistance: bidirectional flow based on water level difference between Basins
  - `LinearResistance / static`: conductances
- TabulatedRatingCurve: Basin outflow relation
  - `TabulatedRatingCurve / static`: rating curve
  - `TabulatedRatingCurve / time`: dynamic rating curve
- Pump: pump water from a source node to a destination node
  - `Pump / static`: flow rate
- Terminal: Water sink without state or properties
  - `Terminal / static`: - (only node IDs)

Adding a geometry to the node table can be helpful to examine models in
[QGIS](https://qgis.org/en/site/), as it will show the location of the nodes on the map. The
geometry is not used by Ribasim.

### Edge

Edges define connections between nodes. Flows between nodes are stored on edges. The only
thing that defines an edge is the nodes it connects, and in what direction. The effect of
the edge direction depends on the node type, Node types that have a notion of an upstream
and downstream side use the incoming edge as the upstream side, and the outgoing edge as the
downstream side. This means that edges should generally be drawn in the main flow direction.
But for instance between two `LinearResistances` the edge direction does not affect
anything, other than the sign of the flow on the edge. The sign of the flow follows the edge
direction; a positive flow flows along the edge direction, a negative flow in the opposite
way.

column         | type     | restriction
-------------- | -------- | -----------
fid            | Int      | unique, sorted
from_node_id   | Int      | -
to_node_id     | Int      | -
geom           | geometry | (optional)

Similarly to the node table, you can use a geometry to visualize the connections between the
nodes in QGIS. For instance, you can draw a line connecting the two node coordinates.

### Basin / state

The state table aims to capture the full state of the Basin, such that it can be used as an
initial condition, potentially the outcome of an earlier simulation. Currently only the
Basin node types have state.

column    | type    | unit         | restriction
--------- | ------- | ------------ | -----------
node_id   | Int     | -            | sorted
storage   | Float64 | $m^3$        | non-negative

Each Basin ID needs to be in the table.

### Basin

The Basin table can be used to set the static value of variables. The forcing table has a
similar schema, with the time column added. A static value for a variable is only used if
there is no dynamic forcing data for that variable. Specifically, if there is either no
forcing table, it is empty, or all timestamps of that variable are missing.

column                | type    | unit         | restriction
---------             | ------- | ------------ | -----------
node_id               | Int     | -            | sorted
precipitation         | Float64 | $m s^{-1}$   | non-negative
potential_evaporation | Float64 | $m s^{-1}$   | non-negative
drainage              | Float64 | $m^3 s^{-1}$ | non-negative
infiltration          | Float64 | $m^3 s^{-1}$ | non-negative
urban_runoff          | Float64 | $m^3 s^{-1}$ | non-negative

Note that if variables are not set in the static table, default values are used when
possible. These are generally zero, e.g. no precipitation, no inflow. If it is not possible
to have a reasonable and safe default, a value must be provided in the static table.

### Basin / forcing

This table is the transient form of the `Basin` table.
The only difference is that a time column is added.
The table must by sorted by time, and per time it must be sorted by node_id.
A linear interpolation between the given timesteps is currently done if the
solver takes timesteps between the given data points. More options will be available later.

### Basin / profile

The profile table defines the physical dimensions of the storage reservoir of each basin.

column    | type    | unit         | restriction
--------- | ------- | ------------ | -----------
node_id   | Int     | -            | sorted
storage   | Float64 | $m^3$        | non-negative, per node_id: start at 0 and increasing
area      | Float64 | $m^2$        | non-negative
level     | Float64 | $m$          | -

The level is the level at the basin outlet. All levels are defined in meters above a datum 
that is the same for the entire model. An example of the first 5 rows of such a table is 
given below. The first 4 rows define the profile of ID `2`. The number of rows can vary 
per ID. Using a very large number of rows may impact performance.

node_id | storage        | area          | level
------- |--------------- |-------------- |-------
      2 |      0.0       |     1.36404e5 | -0.105
      2 |  24726.2       |     1.36404e5 |  0.095
      2 |  49452.5       |     1.36404e5 |  0.295
      2 |      2.49735e6 |     1.36404e5 | 20.095
      3 |      0.0       | 50663.3       |  2.129

### TabulatedRatingCurve

This table is similar in structure to the Basin profile. The TabulatedRatingCurve gives a
relation between the storage of a connected Basin (via the outlet level) and its outflow.

column    | type    | unit         | restriction
--------- | ------- | ------------ | -----------
node_id   | Int     | -            | sorted
level     | Float64 | $m$          | -
discharge | Float64 | $m^3 s^{-1}$ | non-negative

node_id | discharge  | level
------- |----------- |-------
      2 | 0.0        | -0.105
      2 | 0.0        |  0.095
      2 | 0.00942702 |  0.295
      2 | 0.942702   | 20.095
      3 | 0.0        |  2.129

### TabulatedRatingCurve / time

This table is the transient form of the `TabulatedRatingCurve` table.
The only difference is that a time column is added.
The table must by sorted by time, and per time it must be sorted by node_id.
With this the rating curves can be updated over time.
Note that a `node_id` can be either in this table or in the static one, but not both.

column    | type     | unit         | restriction
--------- | -------  | ------------ | -----------
time      | DateTime | -            | sorted
node_id   | Int      | -            | sorted per time
level     | Float64  | $m$          | -
discharge | Float64  | $m^3 s^{-1}$ | non-negative


### Pump

Pump water from a source node to a destination node.
The set flow rate will be pumped unless the intake storage is less than $10~m^3$,
in which case the flow rate will be linearly reduced to $0~m^3/s$.
A negative flow rate means pumping against the edge direction.
Note that the intake must always be a Basin.

column                | type    | unit         | restriction
---------             | ------- | ------------ | -----------
node_id               | Int     | -            | sorted
flow_rate             | Float64 | $m^3 s^{-1}$ | -

### LevelBoundary

Acts like an infinitely large basin where the level does not change by flow. 
This can be connected to a basin via a `LinearResistance`. 
This boundary node will then
exchange water with the basin based on the difference in water level between the two.

column    | type    | unit         | restriction
--------- | ------- | ------------ | -----------
node_id   | Int     | -            | sorted
level     | Float64 | $m^3$        | non-negative


### FlowBoundary

Pump water to a destination node. 
We require that the edge connecting the flow boundary to the Basin should point towards the basin, 
so that positive flow corresponds to water being added to the model.
The set flow rate will be pumped unless the intake storage (for a negative flow rate) is less than $10~m^3$,
in which case the flow rate will be linearly reduced to $0~m^3/s$.
Note that the connected node must always be a Basin.

column                | type    | unit         | restriction
---------             | ------- | ------------ | -----------
node_id               | Int     | -            | sorted
flow_rate             | Float64 | $m^3 s^{-1}$ | -


### Terminal

A terminal is a water sink without state or properties.
Any water that flows into a terminal node is removed from the model.
No water can come into the model from a terminal node.
For example, terminal nodes can be used as a downstream boundary.

column                | type    | unit         | restriction
---------             | ------- | ------------ | -----------
node_id               | Int     | -            | sorted

### Basin output

The basin table contains outputs of the storage and level of each basin at every solver
timestep. The initial condition is also written to the file.

column   | type     | unit
-------- | -------- | ----
time     | DateTime | -
node_id  | Int      | -
storage  | Float64  | $m^3$
level    | Float64  | $m$

The table is sorted by time, and per time it is sorted by node_id.

### Flow output

The flow tables contains outputs of the flow on every edge in the model, for each solver
timestep.

column        | type     | unit
------------- | -------- | ----
time          | DateTime | -
edge_id       | Int      | -
from_node_id  | Int      | -
to_node_id    | Int      | -
flow          | Float64  | $m^3 s^{-1}$

The table is sorted by time, and per time the same edge_id order is used, though not sorted.

## Example input files

From [this link](https://github.com/visr/ribasim-artifacts/releases) you can download an
existing schematization for the Netherlands that was used for testing purposes during
development. It is provided here as an example to help people get started. Based on the
description of the input files above, you can also generate your own schematization using
your tools of choice. For Python users
[ribasim-python](https://github.com/Deltares/ribasim-python) was created to make it easy to
do pre- and postprocessing.
